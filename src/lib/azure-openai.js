// Configuration OpenAI pour l'assistant IA Caddy
// PRIORIT√â : OpenAI direct (plus simple √† configurer)
const OPENAI_API_KEY = process.env.REACT_APP_OPENAI_API_KEY;

// Fallback Azure OpenAI si configur√©
const AZURE_OPENAI_ENDPOINT = process.env.REACT_APP_AZURE_OPENAI_ENDPOINT;
const AZURE_OPENAI_API_KEY = process.env.REACT_APP_AZURE_OPENAI_API_KEY;
const AZURE_OPENAI_DEPLOYMENT_NAME = process.env.REACT_APP_AZURE_OPENAI_DEPLOYMENT_NAME;
const AZURE_OPENAI_API_VERSION = process.env.REACT_APP_AZURE_OPENAI_API_VERSION || '2024-02-15-preview';

if (!OPENAI_API_KEY) {
  console.warn('Configuration OpenAI manquante. Tentative avec Azure OpenAI...');
  if (!AZURE_OPENAI_ENDPOINT || !AZURE_OPENAI_API_KEY || !AZURE_OPENAI_DEPLOYMENT_NAME) {
    console.warn('Aucune cl√© IA trouv√©e. L\'assistant utilisera les r√©ponses simul√©es.');
  }
}

// Configuration de l'assistant IA avec le contexte Caddy
const SYSTEM_PROMPT = `Tu es l'assistant IA de Caddy, une application de gestion d'√©quipes pour le service de lutte contre le gaspillage alimentaire au Luxembourg.

CONTEXTE CADDY :
- Flotte de 5 v√©hicules : Crafter 21, Crafter 23, Jumper, Ducato, Transit
- 21 employ√©s avec profils : Faible/Moyen/Fort
- Langues : Fran√ßais, Arabe, Perse, Espagnol
- Comp√©tences v√©hicules : X (accompagn√©) / XX (autonome)

R√àGLES D'INSERTION SOCIALE :
1. Jamais de profils faibles seuls
2. Associer profils faibles avec profils forts
3. M√©langer les langues pour favoriser l'apprentissage
4. Respecter les comp√©tences v√©hicules

EMPLOY√âS ACTUELS :
- Profils Forts : Martial, Margot, Soroosh, Jos√©, Deazevedo
- Profils Moyens : Ahmad, Imad, Firas, Juan
- Profils Faibles : Shadi, Tamara, Basel, Tesfa, et autres

TU PEUX AIDER AVEC :
- Gestion des absences et r√©organisation automatique
- G√©n√©ration de plannings optimis√©s
- Suggestions d'√©quipes respectant les r√®gles
- Validation de comp√©tences et progression
- Statistiques et rapports

R√âPONDS TOUJOURS EN FRAN√áAIS, de mani√®re concise et professionnelle.`;

export const azureOpenaiAPI = {
  async generateResponse(userMessage) {
    // Essayer OpenAI standard en priorit√© (plus simple)
    if (OPENAI_API_KEY) {
      try {
        console.log('üöÄ Tentative OpenAI standard...');
        return await this.callOpenAIStandard(userMessage);
      } catch (error) {
        console.error('‚ùå Erreur OpenAI standard:', error.message);
        
        // D√©tection d'erreurs r√©seau sp√©cifiques
        if (error.message.includes('net::ERR_NETWORK_CHANGED') || 
            error.message.includes('Failed to fetch') ||
            error.message.includes('network')) {
          console.warn('üåê Probl√®me de connectivit√© r√©seau d√©tect√©');
        }
        
        console.log('üîÑ Tentative avec Azure OpenAI...');
      }
    }

    // Fallback vers Azure OpenAI
    if (AZURE_OPENAI_ENDPOINT && AZURE_OPENAI_API_KEY && AZURE_OPENAI_DEPLOYMENT_NAME) {
      try {
        console.log('üöÄ Tentative Azure OpenAI...');
        return await this.callAzureOpenAI(userMessage);
      } catch (error) {
        console.error('‚ùå Erreur Azure OpenAI:', error.message);
        
        // D√©tection d'erreurs r√©seau sp√©cifiques
        if (error.message.includes('net::ERR_NETWORK_CHANGED') || 
            error.message.includes('Failed to fetch') ||
            error.message.includes('network')) {
          console.warn('üåê Probl√®me de connectivit√© r√©seau d√©tect√© pour Azure aussi');
        }
      }
    }

    // Retourner un message par d√©faut si aucune IA n'est disponible
    console.warn('‚ö†Ô∏è Aucune IA disponible - mode fallback activ√©');
    return this.getFallbackResponse(userMessage);
  },

  // ‚úÖ NOUVEAU : Alias pour compatibilit√© avec le moteur IA
  async chat(userMessage) {
    return await this.generateResponse(userMessage);
  },

  async callAzureOpenAI(userMessage) {
    // Nettoyer l'endpoint (supprimer les slashes en trop)
    const cleanEndpoint = AZURE_OPENAI_ENDPOINT.replace(/\/+$/, '');
    
    // Construire l'URL Azure OpenAI
    const url = `${cleanEndpoint}/openai/deployments/${AZURE_OPENAI_DEPLOYMENT_NAME}/chat/completions?api-version=${AZURE_OPENAI_API_VERSION}`;
    
    console.log('üîç Appel Azure OpenAI:', {
      endpoint: cleanEndpoint,
      deployment: AZURE_OPENAI_DEPLOYMENT_NAME,
      apiVersion: AZURE_OPENAI_API_VERSION
    });

    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': AZURE_OPENAI_API_KEY // Azure utilise 'api-key' au lieu de 'Authorization'
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'system',
            content: SYSTEM_PROMPT
          },
          {
            role: 'user',
            content: userMessage
          }
        ],
        max_tokens: 16000, // üöÄ MEGA-G√âN√âREUX : JSON complexes garantis !
        temperature: 0.7,
        presence_penalty: 0.1,
        frequency_penalty: 0.1
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Erreur Azure OpenAI (${response.status}): ${errorText}`);
    }

    const data = await response.json();
    return data.choices[0]?.message?.content || 'D√©sol√©, je n\'ai pas pu traiter votre demande.';
  },

  async callOpenAIStandard(userMessage) {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4o', // Plus puissant que mini pour JSON complexes
        messages: [
          {
            role: 'system',
            content: SYSTEM_PROMPT
          },
          {
            role: 'user',
            content: userMessage
          }
        ],
        max_tokens: 16000, // üöÄ MEGA-G√âN√âREUX : JSON complexes garantis !
        temperature: 0.7,
        presence_penalty: 0.1,
        frequency_penalty: 0.1
      })
    });

    if (!response.ok) {
      throw new Error(`Erreur API OpenAI: ${response.status}`);
    }

    const data = await response.json();
    return data.choices[0]?.message?.content || 'D√©sol√©, je n\'ai pas pu traiter votre demande.';
  },

  async getFallbackResponse(userMessage = '') {
    // Syst√®me de r√©ponses simul√©es intelligent selon le contexte
    const command = String(userMessage || '').toLowerCase();
    
    // üöõ D√âTECTION PLANNING LOGISTIQUE - Retourner JSON valide
    if (command.includes('logistique') && command.includes('planning')) {
      console.log('üîÑ Mode fallback - Planning logistique JSON structur√©');
      return JSON.stringify({
        "planning_optimal": [],
        "statistiques": {
          "vehicules_utilises": 0,
          "employes_assignes": 0,
          "score_global": 0
        },
        "recommandations": [
          "Mode local activ√© - Configuration IA requise",
          "Utilisez le fallback manuel automatique",
          "V√©rifiez votre connexion r√©seau"
        ],
        "mode": "FALLBACK_NETWORK_ERROR"
      });
    }
    
    if (command.includes('absent') || command.includes('absence')) {
      return `ü§ñ **Assistant IA Caddy (Mode local)**\n\nJe comprends que vous voulez g√©rer une absence. En mode local, je ne peux pas acc√©der aux donn√©es temps r√©el, mais voici la proc√©dure recommand√©e :\n\n1. **Identifier l'employ√©** et sa fonction\n2. **V√©rifier les r√®gles d'insertion sociale**\n3. **Proposer un rempla√ßant** avec profil compatible\n\nüí° *Configurez Azure OpenAI pour des r√©ponses intelligentes !*`;
    }
    
    if (command.includes('planning')) {
      return `ü§ñ **Assistant IA Caddy (Mode local)**\n\nG√©n√©ration de planning en mode simplifi√© :\n\n‚úÖ **R√®gles appliqu√©es :**\n‚Ä¢ Jamais de profils faibles seuls\n‚Ä¢ M√©lange des langues\n‚Ä¢ Respect des comp√©tences v√©hicules\n\nüìä **Suggestion :** Utilisez l'interface de planning pour cr√©er manuellement, ou configurez Azure OpenAI pour la g√©n√©ration automatique.`;
    }
    
    if (command.includes('statistique') || command.includes('rapport')) {
      return `ü§ñ **Assistant IA Caddy (Mode local)**\n\nüìä **Aper√ßu statistiques :**\n‚Ä¢ 21 employ√©s dans l'√©quipe\n‚Ä¢ 5 v√©hicules en service\n‚Ä¢ R√®gles d'insertion sociale actives\n\nüí° *Azure OpenAI permettrait des analyses temps r√©el de vos donn√©es !*`;
    }
    
    return `ü§ñ **Assistant IA Caddy (Mode local)**\n\nJe fonctionne actuellement en mode local. Mes capacit√©s sont limit√©es sans Azure OpenAI.\n\nüîß **Pour une IA compl√®te :**\n‚Ä¢ V√©rifiez votre configuration Azure\n‚Ä¢ Red√©marrez l'application\n‚Ä¢ Testez avec des commandes vocales\n\nüí¨ **Je peux quand m√™me vous aider** avec des conseils g√©n√©raux sur Caddy !`;
  },

  // Test de connexion Azure
  async testConnection() {
    try {
      if (!AZURE_OPENAI_ENDPOINT || !AZURE_OPENAI_API_KEY || !AZURE_OPENAI_DEPLOYMENT_NAME) {
        return {
          success: false,
          error: 'Configuration Azure OpenAI incompl√®te',
          details: {
            endpoint: !!AZURE_OPENAI_ENDPOINT,
            apiKey: !!AZURE_OPENAI_API_KEY,
            deployment: !!AZURE_OPENAI_DEPLOYMENT_NAME
          }
        };
      }

      const response = await this.callAzureOpenAI('Test de connexion');
      
      return {
        success: true,
        message: 'Azure OpenAI op√©rationnel',
        response: response.substring(0, 100) + '...'
      };
      
    } catch (error) {
      return {
        success: false,
        error: error.message,
        fallback: 'OpenAI standard disponible : ' + !!OPENAI_API_KEY
      };
    }
  }
};

// Export pour compatibilit√© avec l'ancien code
export const openaiAPI = azureOpenaiAPI; 